{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHẦN 2- MẠNG THẦN KINH VÀ HỌC SÂU\n",
    "# Chương 10 - Giới thiệu về mạng thần kinh nhân tạo với Keras\n",
    "Trong phần đầu tiên của chương này, chúng tôi sẽ giới thiệu các mạng nơ-ron nhân tạo, bắt đầu bằng việc tham quan nhanh các kiến trúc ANN đầu tiên, dẫn đến các Perceptron nhiều lớp (MLP) được sử dụng nhiều ngày nay (các kiến trúc khác sẽ được khám phá trong các chương tiếp theo). Trong phần thứ hai, chúng ta sẽ xem xét cách triển khai mạng nơ-ron bằng API Keras phổ biến. Đây là một API cấp cao được thiết kế đẹp mắt và đơn giản để xây dựng, đào tạo, đánh giá và chạy các mạng thần kinh. Nhưng đừng để bị lừa bởi sự đơn giản của nó: nó đủ biểu cảm và linh hoạt để cho phép bạn xây dựng nhiều loại kiến trúc mạng nơ-ron. Trong thực tế, nó có thể sẽ đủ cho hầu hết các trường hợp sử dụng của bạn. Hơn nữa, nếu bạn cần thêm tính linh hoạt, bạn luôn có thể viết các thành phần Keras tùy chỉnh bằng cách sử dụng API cấp thấp hơn của nó, như chúng ta sẽ thấy trong Chương 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Từ tế bào thần kinh sinh học đến nhân tạo\n",
    "Đáng ngạc nhiên là ANN đã có từ khá lâu: chúng được giới thiệu lần đầu tiên vào năm 1943 bởi nhà sinh lý học thần kinh Warren McCulloch và nhà toán học Walter Pitts. Trong bài báo mang tính bước ngoặt của họ, 2 “A Logical Calculus of Ideas Immanent in\n",
    "Nervous Activity,”, McCulloch và Pitts đã trình bày một mô hình tính toán đơn giản về cách các tế bào thần kinh sinh học có thể hoạt động cùng nhau trong não động vật để thực hiện các phép tính phức tạp bằng cách sử dụng lôgic mệnh đề. Đây là kiến trúc mạng nơ-ron nhân tạo đầu tiên. Kể từ đó, nhiều kiến trúc khác đã được phát minh, như chúng ta sẽ thấy.\n",
    "\n",
    "Những thành công ban đầu của ANN cho đến những năm 1960 đã dẫn đến niềm tin rộng rãi rằng chúng ta sẽ sớm giao tiếp với những cỗ máy thực sự thông minh. Khi rõ ràng rằng lời hứa này sẽ không được thực hiện (ít nhất là trong một thời gian khá dài), tiền tài trợ đã bay đi nơi khác và ANN đã bước vào một mùa đông dài. Vào đầu những năm 1980, sự quan tâm trở lại đối với chủ nghĩa kết nối (nghiên cứu về mạng nơron), khi các kiến trúc mới được phát minh và các kỹ thuật đào tạo tốt hơn được phát triển. Nhưng tiến độ rất chậm và đến những năm 1990, các kỹ thuật Học máy mạnh mẽ khác đã được phát minh, chẳng hạn như Support Vector Machines (xem Chương 5). Những kỹ thuật này dường như mang lại kết quả tốt hơn và cơ sở lý thuyết vững chắc hơn ANN, vì vậy một lần nữa việc nghiên cứu mạng nơ-ron lại bước vào một mùa đông dài.\n",
    "\n",
    "Cuối cùng, chúng ta đang chứng kiến một làn sóng quan tâm khác đến ANN. Liệu làn sóng này có chết đi như những đợt trước không? Chà, có một vài lý do chính đáng để tin rằng làn sóng này khác và nó sẽ có tác động sâu sắc hơn nhiều đến cuộc sống của chúng ta:\n",
    "\n",
    "- Hiện có một lượng lớn dữ liệu có sẵn để đào tạo mạng nơ-ron và ANN thường làm tốt hơn các kỹ thuật ML khác trong các vấn đề rất lớn và phức tạp\n",
    "- Sự gia tăng vượt bậc về sức mạnh tính toán kể từ những năm 1990 đến nay giúp cho việc đào tạo các mạng nơ-ron lớn trong một khoảng thời gian hợp lý. Điều này một phần là do Định luật Moore, nhưng cũng nhờ vào ngành công nghiệp trò chơi, nơi đã sản xuất ra hàng triệu thẻ GPU mạnh mẽ.\n",
    "- Các thuật toán đào tạo đã được cải thiện. Công bằng mà nói, chúng chỉ khác một chút so với những cái được sử dụng trong những năm 1990, nhưng những chỉnh sửa tương đối nhỏ này lại có tác động tích cực rất lớn.\n",
    "- Một số hạn chế về mặt lý thuyết của ANN hóa ra là không tốt trong thực tế. Ví dụ: nhiều người nghĩ rằng các thuật toán đào tạo ANN đã chết vì chúng có khả năng bị mắc kẹt trong optima cục bộ, nhưng hóa ra điều này khá hiếm trong thực tế (hoặc khi đúng như vậy, chúng thường khá gần với toàn cầu tối ưu).\n",
    "- ANN dường như đã bước vào một vòng tài trợ và tiến bộ tốt. Các sản phẩm tuyệt vời dựa trên ANN thường xuyên xuất hiện trên tiêu đề, điều này thu hút ngày càng nhiều sự chú ý và tài trợ cho họ, dẫn đến ngày càng có nhiều tiến bộ hơn và thậm chí còn có nhiều sản phẩm tuyệt vời hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tế bào thần kinh sinh học\n",
    "Do đó, các tế bào thần kinh sinh học riêng lẻ dường như hoạt động theo một cách khá đơn giản, nhưng chúng được tổ chức trong một mạng lưới rộng lớn hàng tỷ tế bào thần kinh, mỗi tế bào thần kinh thường được kết nối với hàng nghìn tế bào thần kinh khác. Các phép tính có độ phức tạp cao có thể được thực hiện bởi một mạng lưới khổng lồ các nơ-ron khá đơn giản, giống như một con kiến phức tạp có thể xuất hiện từ những nỗ lực tổng hợp của những con kiến đơn giản. Kiến trúc của mạng nơ-ron sinh học (BNN) 4 vẫn là chủ đề của nghiên cứu tích cực, nhưng một số phần của não đã được lập bản đồ, và có vẻ như các nơ-ron thường được tổ chức thành các lớp liên tiếp, như trong Hình 10-2.\n",
    "\n",
    "![](images/10.2.png)\n",
    "*Hình 10.2 Nhiều lớp trong mạng lưới thần kinh sinh học (vỏ não người)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính toán logic với tế bào thần kinh\n",
    "Warren McCulloch và Walter Pitts đã đề xuất một mô hình rất đơn giản của nơ-ron sinh học, sau này được gọi là nơ-ron nhân tạo: nó có một hoặc nhiều đầu vào nhị phân (bật / tắt) và một đầu ra nhị phân. Tế bào thần kinh nhân tạo chỉ đơn giản là kích hoạt đầu ra của nó khi có nhiều hơn một số đầu vào nhất định của nó đang hoạt động. McCulloch và Pitts đã chỉ ra rằng ngay cả với một mô hình đơn giản như vậy, vẫn có thể xây dựng một mạng lưới các nơron nhân tạo tính toán bất kỳ mệnh đề logic nào bạn muốn. Ví dụ: hãy xây dựng một vài ANN thực hiện các phép tính logic khác nhau (xem Hình 10-3), giả sử rằng một nơ-ron được kích hoạt khi ít nhất hai đầu vào của nó đang hoạt động.\n",
    "\n",
    "![](images/10.3.png)\n",
    "\n",
    "*Hình 10.3 ANN đang thực hiện các phép tính logic đơn giản*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mạng đầu tiên bên trái chỉ đơn giản là hàm nhận dạng: nếu nơron A được kích hoạt, thì nơron C cũng sẽ được kích hoạt (vì nó nhận được hai tín hiệu đầu vào từ nơron A), nhưng nếu nơron A tắt, thì nơron C cũng sẽ tắt.\n",
    "- Mạng thứ hai thực hiện AND logic: nơron C chỉ được kích hoạt khi cả hai nơron A và B đều được kích hoạt (một tín hiệu đầu vào duy nhất không đủ để kích hoạt nơron C).\n",
    "- Mạng thứ ba thực hiện OR logic: nơron C được kích hoạt nếu nơron A hoặc nơron B được kích hoạt (hoặc cả hai).\n",
    "- Cuối cùng, nếu chúng ta giả sử rằng một kết nối đầu vào có thể ức chế hoạt động của tế bào thần kinh (trường hợp này xảy ra với các tế bào thần kinh sinh học), thì mạng thứ tư sẽ tính toán một mệnh đề logic phức tạp hơn một chút: nơron C chỉ được kích hoạt nếu nơron A đang hoạt động và nếu nơron B tăt rôi. Nếu nơ-ron A hoạt động mọi lúc, thì bạn sẽ nhận được kết quả KHÔNG hợp lý: nơ-ron C hoạt động khi nơ-ron B tắt và ngược lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "Perceptron là một trong những kiến trúc ANN đơn giản nhất, được phát minh vào năm 1957 bởi Frank Rosenblatt. Nó dựa trên một nơ-ron nhân tạo hơi khác (xem Hình 10-4) được gọi là **threshold logic unit (TLU)**, hoặc đôi khi là **linear threshold unit (LTU)**: đầu vào và đầu ra bây giờ là số (thay vì giá trị bật / tắt nhị phân ) và mỗi kết nối đầu vào được liên kết với một trọng số. TLU tính tổng trọng số của các đầu vào của nó ($z = w_1x_1 + w_2x_2 + ⋯ + w_nx_n = x^Tw$), sau đó áp dụng một hàm bước cho tổng đó và đưa ra kết quả: $h_w(x) = step(z)$, trong đó $z = x^Tw$.\n",
    "\n",
    "![](images/10.4.png)\n",
    "\n",
    "*Hình 10.4 Threshold logic unit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron chỉ đơn giản bao gồm một lớp TLU, với mỗi TLU được kết nối với tất cả các đầu vào. Khi tất cả các tế bào thần kinh trong một lớp được kết nối với mọi tế bào thần kinh trong lớp trước đó (tức là các tế bào thần kinh đầu vào của nó), nó được gọi là lớp kết nối đầy đủ (**fully connected layer**) hoặc lớp dày đặc (**dense layer**). Để biểu thị thực tế là mỗi đầu vào được gửi đến mọi TLU, người ta thường vẽ các tế bào thần kinh truyền qua đặc biệt được gọi là tế bào thần kinh đầu vào (**input neurons**): chúng chỉ xuất ra bất kỳ đầu vào nào mà chúng được cung cấp. Tất cả các nơ-ron đầu vào tạo thành lớp đầu vào. Hơn nữa, một **bias feature** thường được thêm vào ($x_0 = 1$): nó thường được biểu diễn bằng cách sử dụng một loại nơ-ron đặc biệt gọi là **bias neuron**, chỉ xuất ra 1 luôn luôn. Một Perceptron với hai\n",
    "đầu vào và ba đầu ra được biểu diễn trong Hình 10-5. Perceptron này có thể phân loại các cá thể đồng thời thành ba lớp nhị phân khác nhau, điều này làm cho nó trở thành một bộ phân loại đa đầu ra.\n",
    "\n",
    "![](images/10.5.png)\n",
    "\n",
    "*Hình 10.5 Biểu đồ Perceptron*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhờ sự kỳ diệu của đại số tuyến tính, có thể tính toán hiệu quả các kết quả đầu ra của một lớp tế bào thần kinh nhân tạo cho một số trường hợp cùng một lúc, bằng cách sử dụng Công thức: \n",
    "Tính toán đầu ra của một lớp được kết nối đầy đủ $h_{W, b}(X) = ϕ(XW + b)$\n",
    "- $X$ đại diện cho ma trận các tính năng đầu vào. Nó có một hàng cho mỗi trường hợp, một cột cho mỗi tính năng.\n",
    "- Ma trận trọng số $W$ chứa tất cả các trọng số kết nối ngoại trừ các trọng số từ bias neuron . Nó có một hàng cho mỗi nơ-ron đầu vào và một cột cho mỗi nơ-ron nhân tạo trong lớp.\n",
    "- Vectơ bias $b$ chứa tất cả các trọng số kết nối giữa bias neuron và nơ-ron nhân tạo.\n",
    "- Hàm $ϕ$ được gọi là hàm kích hoạt (**activation function**): khi tế bào thần kinh nhân tạo là TLU, nó là một hàm bước (nhưng chúng ta sẽ thảo luận về các hàm kích hoạt khác ngay sau đây)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron được cung cấp một phiên bản huấn luyện tại một thời điểm và đối với mỗi trường hợp, nó đưa ra các dự đoán của nó. Đối với mỗi nơ-ron đầu ra tạo ra một dự đoán sai, nó củng cố trọng số kết nối từ các đầu vào mà lẽ ra sẽ góp phần vào dự đoán đúng. Quy tắc được hiển thị trong Công thức 10-3. \\\n",
    "Quy tắc học tập Perceptron (cập nhật trọng lượng): $w_{i, j}^{(next step)}= w_{i, j} + η(y_j − \\hat{y_j}) x_i$\n",
    "- $W_{i ,j}$ là trọng số kết nối giữa nơron đầu vào thứ $i$ và nơron đầu ra thứ $j$.\n",
    "- $x_i$ là giá trị đầu vào thứ $i$ của phiên bản huấn luyện hiện tại.\n",
    "- $\\hat{y_j}$ là đầu ra của nơron đầu ra thứ $j$ cho phiên bản huấn luyện hiện tại.\n",
    "- $y_j$ là đầu ra đích của nơron đầu ra thứ $j$ cho phiên bản huấn luyện hiện tại.\n",
    "- $η$ là learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit-Learn** cung cấp một lớp `Perceptron` triển khai một mạng TLU duy nhất. Nó có thể được sử dụng khá nhiều như bạn mong đợi — ví dụ: trên tập dữ liệu iris (được giới thiệu trong Chương 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # chiều dài cánh hoa, chiều rộng cánh hoa\n",
    "y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có thể nhận thấy thực tế là thuật toán học Perceptron rất giống với **Stochastic Gradient Descent**. Trên thực tế, lớp Scikit-Learn’s Perceptron tương đương với việc sử dụng `SGDClassifier` với các siêu tham số sau: `loss = \"perceptron\"`, `learning_rate = \"constant\"`, `eta0 = 1` (tốc độ học tập) và hình phạt = Không (không chính quy).\n",
    "\n",
    "Tuy nhiên, nó chỉ ra rằng một số hạn chế của Perceptron có thể được loại bỏ bằng cách xếp chồng nhiều Perceptron. ANN kết quả được gọi là **Multi-Layer Perceptron (MLP)**. Đặc biệt, một MLP có thể giải quyết vấn đề XOR, vì bạn có thể xác minh bằng cách tính toán đầu ra của MLP được biểu diễn ở bên phải của Hình 10-6: với đầu vào (0,0) hoặc (1, 1) mạng đầu ra 0, và với các đầu vào (0, 1) hoặc (1, 0) thì đầu ra là 1. Tất cả các kết nối có trọng số bằng 1, ngoại trừ bốn kết nối có trọng số được hiển thị. Hãy thử xác minh rằng mạng này thực sự giải quyết được vấn đề XOR!\n",
    "\n",
    "![](images/10.6.png)\n",
    "\n",
    "*Hình 10.6 Vấn đề phân loại XOR và MLP giải quyết nó*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron and Backpropagation\n",
    "MLP bao gồm một lớp đầu vào (truyền qua), một hoặc nhiều lớp TLU, được gọi là lớp ẩn và một lớp cuối cùng của TLU được gọi là lớp đầu ra (xem Hình 10-7). Các lớp gần với lớp đầu vào thường được gọi là lớp dưới (lower layers), và những lớp gần với đầu ra thường được gọi là lớp trên (upper layers). Mọi lớp ngoại trừ lớp đầu ra bao gồm một bias neuron và được kết nối đầy đủ với lớp tiếp theo.\n",
    "\n",
    "![](images/10.7.png)\n",
    "\n",
    "*Hình 10.7 Multi-Layer Perceptron*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi một ANN chứa một chồng sâu các lớp ẩn (hidden layers), nó được gọi là mạng nơ-ron sâu (DNN). Lĩnh vực Học sâu nghiên cứu các DNN và nói chung là các mô hình có chứa các tính toán sâu. \n",
    "\n",
    "Trong nhiều năm, các nhà nghiên cứu đã vật lộn để tìm cách đào tạo MLP nhưng không thành công. Nhưng vào năm 1986, David Rumelhart, Geoffrey Hinton và Ronald Williams đã xuất bản một bài báo (*Learning Internal Representations by Error Propagation,*) đột phá giới thiệu thuật toán đào tạo lan truyền ngược, thuật toán này vẫn được sử dụng cho đến ngày nay. Nói tóm lại, nó chỉ đơn giản là Gradient Descent (được giới thiệu trong Chương 4) sử dụng một kỹ thuật hiệu quả để tính toán gradient một cách tự động: chỉ trong hai lần đi qua mạng (một tiến, một lùi), **thuật toán backpropagation** có thể tính toán gradient của lỗi của mạng liên quan đến mọi thông số mô hình đơn lẻ. Nói cách khác, nó có thể tìm ra cách điều chỉnh từng trọng số kết nối và từng thuật ngữ thiên vị để giảm lỗi. Một khi nó có các gradient này, nó chỉ thực hiện một bước Gradient Descent thông thường và toàn bộ quá trình được lặp lại cho đến khi mạng hội tụ đến giải pháp.\n",
    "\n",
    "Hãy chạy qua thuật toán này chi tiết hơn một chút:\n",
    "\n",
    "- Nó xử lý một mini-batch tại một thời điểm (ví dụ: mỗi đợt chứa 32 phiên bản) và nó trải qua toàn bộ tập huấn luyện nhiều lần. Mỗi lần vượt qua được gọi là epoch, như chúng ta đã thấy trong Chương 4.\n",
    "- Mỗi Mini-batch được chuyển đến lớp đầu vào của mạng, lớp này chỉ gửi đến lớp ẩn đầu tiên. Sau đó, thuật toán sẽ tính toán đầu ra của tất cả các nơ-ron trong lớp này (đối với mọi trường hợp trong lô nhỏ). Kết quả được chuyển cho lớp tiếp theo, đầu ra của nó được tính toán và chuyển cho lớp tiếp theo, và cứ tiếp tục như vậy cho đến khi chúng ta nhận được kết quả của lớp cuối cùng, lớp đầu ra. Đây là chuyển tiếp (forward pass): nó giống hệt như đưa ra dự đoán, ngoại trừ tất cả các kết quả trung gian được giữ nguyên vì chúng cần thiết cho chuyển tiếp.\n",
    "- Tiếp theo, thuật toán đo lường lỗi đầu ra của mạng (tức là nó sử dụng hàm mất mát so sánh đầu ra mong muốn và đầu ra thực tế của mạng và trả về một số phép đo lỗi).\n",
    "- Sau đó, thuật toán đo lường mức độ đóng góp lỗi này đến từ mỗi kết nối trong lớp bên dưới, một lần nữa sử dụng quy tắc chuỗi — và cứ tiếp tục như vậy cho đến khi thuật toán đạt đến lớp đầu vào. Như chúng tôi đã giải thích trước đó, phép truyền ngược này đo lường hiệu quả gradient lỗi trên tất cả các trọng số kết nối trong mạng bằng cách truyền ngược gradient lỗi qua mạng (do đó có tên là thuật toán).\n",
    "- Cuối cùng, thuật toán thực hiện bước Gradient Descent để điều chỉnh tất cả các trọng số kết nối trong mạng, sử dụng các gradient lỗi mà nó vừa tính toán."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thuật toán này rất quan trọng, đáng để tóm tắt lại: đối với mỗi trường hợp huấn luyện, thuật toán lan truyền ngược đầu tiên đưa ra dự đoán (chuyển tiếp), đo lỗi, sau đó đi qua từng lớp ngược lại để đo mức đóng góp lỗi từ mỗi kết nối (chuyển ngược ), và cuối cùng là tinh chỉnh một chút trọng số kết nối để giảm lỗi (bước Gradient Descent).\n",
    "\n",
    "Để thuật toán này hoạt động bình thường, các tác giả đã thực hiện một thay đổi quan trọng đối với kiến trúc của MLP: họ thay thế hàm bước bằng hàm logistic, $σ(z) = 1 / (1 + exp (–z))$. Điều này rất cần thiết vì hàm bước chỉ chứa các phân đoạn phẳng, do đó không có gradient để làm việc (Gradient Descent không thể di chuyển trên một bề mặt phẳng), trong khi hàm logistic có đạo hàm khác không được xác định rõ ràng ở mọi nơi, cho phép Gradient Descent tạo ra một số tiến bộ ở mỗi bước. Trên thực tế, thuật toán backpropagation hoạt động tốt với nhiều activation functions khác, không chỉ với chức năng logistic. Hai **activation functions** phổ biến khác là:\n",
    "- **The hyperbolic tangent function $tanh(z) = 2σ(2z) – 1$**: \\\n",
    "Cũng giống như hàm logistic, nó có hình chữ S, liên tục và có thể phân biệt được, nhưng giá trị đầu ra của nó nằm trong khoảng –1 đến 1 (thay vì 0 đến 1 trong trường hợp của hàm logistic), có xu hướng làm cho đầu ra của mỗi lớp nhiều hơn hoặc ít tập trung vào khoảng 0 khi bắt đầu đào tạo. Điều này thường giúp tăng tốc độ hội tụ.\n",
    "- **The Rectified Linear Unit function: $ReLU(z) = max(0, z)$** \\\n",
    "Nó liên tục nhưng không may là không phân biệt được tại $z = 0$ (độ dốc thay đổi đột ngột, có thể làm cho Gradient Descent nảy xung quanh), và đạo hàm của nó là 0 đối với $z <0$. Tuy nhiên, trong thực tế, nó hoạt động rất tốt và có lợi thế là nhanh chóng để tính toán. Quan trọng nhất, thực tế là nó không có giá trị đầu ra tối đa cũng giúp giảm một số vấn đề trong quá trình Gradient Descent (chúng ta sẽ quay lại vấn đề này trong Chương 11).\n",
    "\n",
    "![](images/10.8.png)\n",
    "\n",
    "*Hình 10.8 Activation functions and their derivatives*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hồi quy MPL\n",
    "Đầu tiên, MLP có thể được sử dụng cho các nhiệm vụ hồi quy. Nếu bạn muốn dự đoán một giá trị duy nhất (ví dụ: giá của một ngôi nhà có nhiều tính năng của nó), thì bạn chỉ cần một nơ-ron đầu ra duy nhất: đầu ra của nó là giá trị dự đoán. Đối với hồi quy đa biến (tức là để dự đoán nhiều giá trị cùng một lúc), bạn cần một nơ-ron đầu ra cho mỗi thứ nguyên đầu ra. Ví dụ, để xác định vị trí trung tâm của một đối tượng trên hình ảnh, bạn cần dự đoán tọa độ 2D, vì vậy bạn cần hai nơ-ron đầu ra. Nếu bạn cũng muốn đặt một hộp giới hạn xung quanh đối tượng, thì bạn cần thêm hai số: chiều rộng và chiều cao của đối tượng. Vì vậy, bạn kết thúc với 4 nơ-ron đầu ra.\n",
    "\n",
    "Nói chung, khi xây dựng MLP cho hồi quy, bạn không muốn sử dụng bất kỳ hàm kích hoạt nào cho các nơron đầu ra, vì vậy chúng có thể tự do xuất ra bất kỳ dải giá trị nào. Tuy nhiên, nếu bạn muốn đảm bảo rằng đầu ra sẽ luôn dương, thì bạn có thể sử dụng chức năng kích hoạt ReLU hoặc chức năng kích hoạt softplus trong lớp đầu ra. Cuối cùng, nếu bạn muốn đảm bảo rằng các dự đoán sẽ nằm trong một phạm vi giá trị, sau đó bạn có thể sử dụng hàm logistic hoặc tiếp tuyến hyperbol và chia tỷ lệ các nhãn thành phạm vi thích hợp: 0 đến 1 cho hàm logistic hoặc –1 đến 1 cho tiếp tuyến hyperbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kiến trúc MLP hồi quy điển hình*\n",
    "\n",
    "| Hyperparameter  \t| Typical Value \t|\n",
    "|-\t|-\t|\n",
    "| # input neurons  \t| One per input feature (e.g., 28 x 28 = 784 for MNIST) \t|\n",
    "| # hidden layers \t| Depend on the problem. Typically 1 to 5 \t|\n",
    "| # neurons per hidden layer Depends on the problem. Typically 10 to 100. \t| Depend on the problem. Typically 10 to 100 \t|\n",
    "| # output neurons  \t| 1 per prediction dimension \t|\n",
    "| Hidden activation  \t| ReLU (or SELU, see Chapter 11) \t|\n",
    "| Output activation  \t| None or ReLU/Softplus (if positive outputs) or Logistic/Tanh (if bounded outputs) \t|\n",
    "| Output activation  \t| None or ReLU/Softplus (if positive outputs) or Logistic/Tanh (if bounded outputs) \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân loại bằng MLP\n",
    "MLP cũng có thể được sử dụng cho các nhiệm vụ phân loại. Đối với bài toán phân loại nhị phân, bạn chỉ cần một nơ-ron đầu ra duy nhất sử dụng hàm kích hoạt logistic: đầu ra sẽ là một số từ 0 đến 1, mà bạn có thể hiểu là xác suất ước tính của lớp dương. Rõ ràng, xác suất ước tính của lớp phủ định bằng một trừ đi số đó.\n",
    "\n",
    "MLP cũng có thể dễ dàng xử lý các nhiệm vụ phân loại nhị phân đa nhãn (xem Chương 3). Ví dụ: bạn có thể có một hệ thống phân loại email dự đoán liệu mỗi email đến là thư rác hay thư rác, đồng thời dự đoán đó là email khẩn cấp hay không khẩn cấp. Trong trường hợp này, bạn sẽ cần hai nơ-ron đầu ra, cả hai đều sử dụng chức năng kích hoạt hậu cần: đầu tiên sẽ xuất ra xác suất email đó là thư rác và thứ hai sẽ xuất ra xác suất email đó là khẩn cấp. Nói chung hơn, bạn sẽ dành một nơ-ron đầu ra cho mỗi lớp tích cực. Lưu ý rằng các xác suất đầu ra không nhất thiết phải cộng vào một. Điều này cho phép mô hình xuất ra bất kỳ tổ hợp nhãn nào: bạn có thể có ham không khẩn cấp, ham khẩn cấp, thư rác không khẩn cấp và thậm chí có thể là thư rác khẩn cấp (mặc dù đó có thể là một lỗi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu mỗi cá thể chỉ có thể thuộc về một lớp duy nhất, trong số 3 lớp có thể có trở lên (ví dụ: từ lớp 0 đến lớp 9 để phân loại hình ảnh chữ số), thì bạn cần có một nơ-ron đầu ra cho mỗi lớp và bạn nên sử dụng hàm kích hoạt softmax cho toàn bộ lớp đầu ra (xem Hình 10-9). Hàm softmax (được giới thiệu trong Chương 4) sẽ đảm bảo rằng tất cả các xác suất ước tính nằm trong khoảng từ 0 đến 1 và chúng cộng lại thành một (bắt buộc nếu các lớp là riêng biệt). Đây được gọi là  **multiclass classification**.\n",
    "\n",
    "![](images/10.9.png)\n",
    "\n",
    "*Hình 10.9 Một MLP hiện đại (bao gồm ReLU và softmax) để phân loại*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Phân loại điển hình Kiến trúc MLP*\n",
    "\n",
    "| Hyperparameter| Hyperparameter| Multilabel binary classification |Multilabel binary classification |\n",
    "|----------|:-------------:|------:|-:|\n",
    "| Input and hidden layers |  Same as regression | Same as regression | Same as regression|\n",
    "| # output neurons |    1   | 1 per label|1 per class |\n",
    "| Output layer activation | Logistic |   Logistic| Softmax|\n",
    "| Loss function| Loss function |   Loss function | Loss function|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Triển khai MLP với Keras\n",
    "![](images/10.10.png)\n",
    "* Hình 10.10 Hai triển khai Keras: keras-team (trái) và tf.keras (phải)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng bộ phân loại hình ảnh bằng API tuần tự\n",
    "Đầu tiên, chúng ta cần tải một tập dữ liệu. Chúng tôi sẽ đề cập đến Thời trang MNIST, là sản phẩm thay thế MNIST (được giới thiệu trong Chương 3). Nó có định dạng giống hệt như MNIST (70.000 hình ảnh thang độ xám 28 × 28 pixel mỗi lớp, với 10 lớp), nhưng các hình ảnh đại diện cho các mặt hàng thời trang chứ không phải chữ số viết tay, vì vậy mỗi lớp đa dạng hơn và vấn đề trở nên nhiều hơn đáng kể thách thức hơn MNIST. Ví dụ: một mô hình tuyến tính đơn giản đạt độ chính xác khoảng 92% trên MNIST, nhưng chỉ đạt khoảng 83% trên Fashion MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sử dụng Keras để tải tập dữ liệu\n",
    "Keras cung cấp một số chức năng tiện ích để tìm nạp và tải các tập dữ liệu chung, bao gồm MNIST, Fashion MNIST, tập dữ liệu nhà ở California ban đầu, v.v. Hãy tải Thời trang MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi tải MNIST hoặc Fashion MNIST bằng Keras thay vì Scikit-Learn, một điểm khác biệt quan trọng là mọi hình ảnh được biểu thị dưới dạng mảng 28 × 28 thay vì mảng 1D có kích thước 784. Hơn nữa, cường độ pixel được biểu thị dưới dạng số nguyên (từ 0 đến 255) chứ không phải float (từ 0,0 đến 255,0). Đây là hình dạng và kiểu dữ liệu của tập huấn luyện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng tập dữ liệu đã được chia thành tập huấn luyện và tập thử nghiệm, nhưng không có tập hợp xác thực nào, vì vậy hãy tạo một tập hợp. Hơn nữa, vì chúng ta sẽ đào tạo mạng nơ-ron bằng cách sử dụng Gradient Descent, chúng ta phải mở rộng các tính năng đầu vào. Để đơn giản, chúng tôi chỉ cần chia tỷ lệ cường độ pixel xuống phạm vi 0-1 bằng cách chia chúng cho 255,0 (điều này cũng chuyển đổi chúng thành float):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với MNIST, khi nhãn bằng 5, có nghĩa là hình ảnh đại diện cho chữ số 5. Dễ dàng. Tuy nhiên, đối với Fashion MNIST, chúng tôi cần danh sách tên lớp để biết chúng tôi đang xử lý những gì:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ: hình ảnh đầu tiên trong tập huấn luyện đại diện cho một chiếc áo khoác (Coat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/10.11.png)\n",
    "\n",
    "*Mẫu từ Thời trang MNIST*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tạo mô hình bằng API tuần tự\n",
    "Bây giờ chúng ta hãy xây dựng mạng nơ-ron! Đây là một MLP phân loại với hai lớp ẩn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thay vì thêm từng lớp một như chúng ta vừa làm, bạn có thể chuyển danh sách các lớp khi tạo mô hình `Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phương thức `summary()` của mô hình hiển thị tất cả các lớp của mô hình, bao gồm tên của mỗi lớp (được tạo tự động trừ khi bạn đặt nó khi tạo lớp), hình dạng đầu ra của nó (Không có nghĩa là kích thước lô có thể là bất kỳ thứ gì) và số lượng tham số của nó . Bản tóm tắt kết thúc với tổng số tham số, bao gồm cả tham số có thể đào tạo và không thể đào tạo. Ở đây chúng ta chỉ có các tham số có thể huấn luyện (chúng ta sẽ xem các ví dụ về các tham số không thể huấn luyện trong Chương 11):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng các lớp dày đặc thường có rất nhiều tham số. Ví dụ, ẩn đầu tiên\n",
    "lớp có trọng số kết nối 784 × 300, cộng với 300 bias, bổ sung tới 235.500 tham số! Điều này mang lại cho mô hình khá nhiều tính linh hoạt để phù hợp với dữ liệu đào tạo, nhưng nó cũng có nghĩa là mô hình có nguy cơ bị **overfitting**, đặc biệt là khi bạn **không có nhiều dữ liệu đào tạo**. Chúng ta sẽ quay lại vấn đề này sau.\n",
    "\n",
    "Bạn có thể dễ dàng lấy danh sách các lớp của một mô hình, tìm một lớp theo index của nó hoặc bạn có thể tìm nó theo tên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1c5691a48e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c5691a4e80>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c5691a4df0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c5691a4370>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3').name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tất cả các tham số của một lớp có thể được truy cập bằng cách sử dụng phương thức `get_weights()` và `set_weights()` của nó. Đối với lớp dày đặc, điều này bao gồm cả trọng số kết nối (connection weights) và bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01779534, -0.0332581 ,  0.06308945, ...,  0.06810673,\n",
       "         0.07084629,  0.05733261],\n",
       "       [ 0.07201517, -0.00137161, -0.04810912, ...,  0.01663743,\n",
       "         0.06149785, -0.05780075],\n",
       "       [ 0.02605529, -0.04023733,  0.06733866, ..., -0.04233471,\n",
       "        -0.01234251, -0.00330196],\n",
       "       ...,\n",
       "       [ 0.02947579,  0.008687  ,  0.05391216, ...,  0.01034874,\n",
       "        -0.00653452,  0.0372804 ],\n",
       "       [ 0.03735267, -0.03441594,  0.05491158, ..., -0.03469758,\n",
       "        -0.03091507,  0.02269994],\n",
       "       [-0.03750242,  0.0018185 ,  0.00384697, ...,  0.07397765,\n",
       "        -0.05283204,  0.01387827]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng lớp Dense khởi tạo trọng số kết nối một cách ngẫu nhiên (đó là\n",
    "cần thiết để phá vỡ tính đối xứng, như chúng ta đã thảo luận trước đó), và các thành kiến chỉ được khởi tạo thành số không, điều này tốt. Nếu bạn muốn sử dụng một phương thức khởi tạo khác, bạn có thể đặt kernel_initializer (kernel là tên khác của ma trận trọng số kết nối) hoặc bias_initializer khi tạo lớp. Chúng ta sẽ thảo luận thêm về các trình khởi tạo trong Chương 11, nhưng nếu bạn muốn có danh sách đầy đủ, hãy xem https://keras.io/initializers/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biên dịch mô hình\n",
    "Sau khi một mô hình được tạo, bạn phải gọi phương thức `compile()` của nó để chỉ định hàm mất mát và trình tối ưu hóa để sử dụng. Theo tùy chọn, bạn cũng có thể chỉ định danh sách các chỉ số bổ sung để tính toán trong quá trình đào tạo và đánh giá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều này cần một số lời giải thích. Đầu tiên, chúng tôi sử dụng `\"precision_categorical_crossen\"` tropy \"mất mát bởi vì chúng ta có các nhãn thưa thớt (nghĩa là đối với mỗi trường hợp chỉ có một chỉ mục lớp mục tiêu, từ 0 đến 9 trong trường hợp này) và các lớp là độc quyền. Nếu thay vào đó, chúng ta có một xác suất mục tiêu cho mỗi lớp cho mỗi trường hợp ( chẳng hạn như vectơ một nóng, ví dụ `[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]` để đại diện cho lớp 3), thì chúng ta sẽ cần để sử dụng `\"categorical_crossentropy\"` thay thế. Nếu chúng ta đang thực hiện phân loại nhị phân (với một hoặc nhiều nhãn nhị phân), thì chúng ta sẽ sử dụng hàm kích hoạt `\"sigmoid\"` (tức là logistic) trong lớp đầu ra thay vì hàm kích hoạt `\"softmax\"` và chúng ta sẽ sử dụng `\"binary_crossentropy\"` loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thứ hai, liên quan đến trình tối ưu hóa, `\"sgd\"` chỉ đơn giản có nghĩa là chúng ta sẽ đào tạo mô hình bằng cách sử dụng Stochastic Gradient Descent đơn giản. Nói cách khác, Keras sẽ thực hiện thuật toán lan truyền ngược được mô tả trước đó (tức là autodiff chế độ đảo ngược + Gradient Descent). Chúng ta sẽ thảo luận về các trình tối ưu hóa hiệu quả hơn trong Chương 11 (chúng cải thiện phần Gradient Descent, không phải autodiff).\n",
    "\n",
    "Cuối cùng, vì đây là một bộ phân loại, nên rất hữu ích khi đo `\"accuracy\"` của nó trong quá trình đào tạo và đánh giá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đào tạo và đánh giá mô hình\n",
    "Bây giờ mô hình đã sẵn sàng để được đào tạo. Đối với điều này, chúng ta chỉ cần gọi phương thức `fit()` của nó. Chúng tôi chuyển cho nó các tính năng đầu vào (`X_train`) và các lớp mục tiêu (`y_train`), cũng như số kỷ nguyên cần đào tạo (hoặc nếu không, nó sẽ mặc định chỉ là 1, điều này chắc chắn sẽ không đủ để hội tụ thành một giải pháp tốt). Chúng tôi cũng vượt qua một tập hợp xác thực (đây là tùy chọn): Keras sẽ đo lường tổn thất và các chỉ số bổ sung trên tập hợp này vào cuối mỗi kỷ nguyên, điều này rất hữu ích để xem mô hình thực sự hoạt động tốt như thế nào: nếu hiệu suất trên đào tạo set tốt hơn nhiều so với trên tập hợp xác thực, mô hình của bạn có thể được trang bị quá mức tập hợp đào tạo (hoặc có lỗi, chẳng hạn như dữ liệu không khớp giữa tập hợp đào tạo và tập hợp xác thực):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7266 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.8278\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4902 - accuracy: 0.8278 - val_loss: 0.4577 - val_accuracy: 0.8506\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4442 - accuracy: 0.8435 - val_loss: 0.4200 - val_accuracy: 0.8516\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4164 - accuracy: 0.8541 - val_loss: 0.4040 - val_accuracy: 0.8650\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3963 - accuracy: 0.8607 - val_loss: 0.3928 - val_accuracy: 0.8682\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3800 - accuracy: 0.8652 - val_loss: 0.3760 - val_accuracy: 0.8686\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3653 - accuracy: 0.8707 - val_loss: 0.3726 - val_accuracy: 0.8722\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3548 - accuracy: 0.8735 - val_loss: 0.3766 - val_accuracy: 0.8678\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3441 - accuracy: 0.8773 - val_loss: 0.3502 - val_accuracy: 0.8780\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3350 - accuracy: 0.8807 - val_loss: 0.3423 - val_accuracy: 0.8814\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8841 - val_loss: 0.4056 - val_accuracy: 0.8654\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3192 - accuracy: 0.8861 - val_loss: 0.3451 - val_accuracy: 0.8768\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3122 - accuracy: 0.8880 - val_loss: 0.3547 - val_accuracy: 0.8736\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3038 - accuracy: 0.8916 - val_loss: 0.3306 - val_accuracy: 0.8832\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2982 - accuracy: 0.8929 - val_loss: 0.3363 - val_accuracy: 0.8782\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2916 - accuracy: 0.8940 - val_loss: 0.3182 - val_accuracy: 0.8880\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2852 - accuracy: 0.8971 - val_loss: 0.3215 - val_accuracy: 0.8884\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2799 - accuracy: 0.8997 - val_loss: 0.3115 - val_accuracy: 0.8906\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2737 - accuracy: 0.9017 - val_loss: 0.3180 - val_accuracy: 0.8890\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2692 - accuracy: 0.9028 - val_loss: 0.3227 - val_accuracy: 0.8830\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2641 - accuracy: 0.9058 - val_loss: 0.3077 - val_accuracy: 0.8898\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2601 - accuracy: 0.9071 - val_loss: 0.3153 - val_accuracy: 0.8886\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2551 - accuracy: 0.9082 - val_loss: 0.3146 - val_accuracy: 0.8930\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2512 - accuracy: 0.9093 - val_loss: 0.3283 - val_accuracy: 0.8786\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2460 - accuracy: 0.9109 - val_loss: 0.3007 - val_accuracy: 0.8972\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2431 - accuracy: 0.9121 - val_loss: 0.3068 - val_accuracy: 0.8896\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2380 - accuracy: 0.9137 - val_loss: 0.3252 - val_accuracy: 0.8864\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2341 - accuracy: 0.9160 - val_loss: 0.3115 - val_accuracy: 0.8922\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2303 - accuracy: 0.9177 - val_loss: 0.3125 - val_accuracy: 0.8868\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2261 - accuracy: 0.9190 - val_loss: 0.3164 - val_accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và thế là xong! Mạng nơron được đào tạo. Tại mỗi thời điểm trong quá trình đào tạo, Keras hiển thị số lượng phiên bản đã xử lý cho đến nay (cùng với thanh tiến trình), thời gian đào tạo trung bình cho mỗi mẫu, độ hao hụt và độ chính xác (hoặc bất kỳ số liệu bổ sung nào khác mà bạn yêu cầu), cả trên bộ đào tạo và bộ xác nhận. Bạn có thể thấy rằng sự mất mát trong quá trình huấn luyện đã giảm xuống, đó là một dấu hiệu tốt và độ chính xác xác nhận đạt 87,28% sau 50 kỷ nguyên, không quá xa so với độ chính xác khi luyện tập, vì vậy dường như không có nhiều quá khớp xảy ra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phương thức `fit()` trả về một đối tượng Lịch sử có chứa các tham số huấn luyện (`history.params`), danh sách các kỷ nguyên mà nó đã trải qua (`history.epoch`) và quan trọng nhất là một từ điển (`history.history`) chứa các số liệu mất mát và bổ sung mà nó đo được ở cuối mỗi kỷ nguyên trên tập huấn luyện và xác thực bộ (nếu có). Nếu bạn tạo một Pandas DataFrame bằng cách sử dụng từ điển này và gọi phương thức `plot()` của nó, bạn sẽ nhận được các đường cong học tập được hiển thị trong Hình 10-12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có thể thấy rằng độ chính xác của cả quá trình đào tạo và xác thực đều tăng đều đặn trong quá trình đào tạo, trong khi mất mát trong quá trình đào tạo và xác nhận giảm. Tốt! Hơn nữa, các đường cong validation khá gần với đường cong training, có nghĩa là không có quá nhiều overfitting. Trong trường hợp cụ thể này, mô hình hoạt động tốt hơn trên bộ xác thực so với bộ đào tạo khi bắt đầu đào tạo: điều này đôi khi xảy ra một cách tình cờ (đặc biệt là khi bộ xác thực khá nhỏ). Tuy nhiên, hiệu suất tập luyện kết thúc đánh bại hiệu suất xác nhận, như thường là trường hợp bạn luyện tập đủ lâu. Bạn có thể nói rằng mô hình vẫn chưa hoàn toàn hội tụ, vì mất xác thực vẫn đang giảm, vì vậy bạn có thể nên tiếp tục đào tạo. Nó đơn giản như việc gọi lại phương thức `fit()`, vì Keras chỉ tiếp tục đào tạo khi nó đã dừng lại (bạn sẽ có thể đạt độ chính xác xác thực gần 89%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu bạn không hài lòng với hiệu suất của mô hình của mình, bạn nên quay lại và điều chỉnh các siêu tham số của mô hình, ví dụ như số lớp, số lượng tế bào thần kinh trên mỗi lớp, các loại chức năng kích hoạt chúng tôi sử dụng cho mỗi lớp ẩn, số của các kỷ nguyên đào tạo, kích thước lô (nó có thể được đặt trong phương thức `fit()` bằng cách sử dụng đối số `batch_size`, mặc định là 32). Chúng ta sẽ quay lại điều chỉnh siêu tham số ở cuối chương này. Sau khi hài lòng với độ chính xác xác thực của mô hình, bạn nên đánh giá mô hình đó trên bộ thử nghiệm để ước tính lỗi tổng quát trước khi triển khai mô hình vào sản xuất. Bạn có thể dễ dàng thực hiện việc này bằng cách sử dụng phương thức `eval()` (nó cũng hỗ trợ một số đối số khác, chẳng hạn như `batch_size` hoặc `sample_weight`, vui lòng kiểm tra tài liệu để biết thêm chi tiết):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 75.4750 - accuracy: 0.8451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[75.47498321533203, 0.8450999855995178]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sử dụng mô hình để đưa ra dự đoán\n",
    "Tiếp theo, chúng tôi có thể sử dụng phương thức `predict()` của mô hình để đưa ra dự đoán về các phiên bản mới. Vì chúng tôi không có phiên bản mới thực tế, chúng tôi sẽ chỉ sử dụng 3 phiên bản đầu tiên của tập hợp thử nghiệm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như bạn có thể thấy, đối với mỗi trường hợp, mô hình ước tính một xác suất cho mỗi lớp, từ lớp 0 đến lớp 9. Ví dụ: đối với hình ảnh đầu tiên, nó ước tính rằng xác suất của lớp 9 (ankle boot) là 79%, xác suất của lớp 7 (sneaker) là 12%, xác suất của lớp 5 (sandal) là 9%, và các lớp khác là không đáng kể. Nói cách khác, nó\n",
    "“Tin tưởng” đó là giày dép, có thể là bốt đến mắt cá chân, nhưng không hoàn toàn chắc chắn, thay vào đó có thể là giày thể thao hoặc dép xăng đan. Nếu bạn chỉ quan tâm đến lớp có xác suất ước tính cao nhất (ngay cả khi xác suất đó khá thấp) thì bạn có thể sử dụng phương thức `pre dict_classes()` thay thế:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng MLP hồi quy bằng API tuần tự (Sequential API)\n",
    "Hãy chuyển sang vấn đề nhà ở ở California và giải quyết nó bằng cách sử dụng mạng nơ-ron hồi quy. Để đơn giản, chúng tôi sẽ sử dụng Scikit-Learn’s `fetch_california_housing()` hàm tải dữ liệu: tập dữ liệu này đơn giản hơn tập dữ liệu mà chúng ta đã sử dụng trong Chương 2, vì nó chỉ chứa các đặc trưng số (không có tính năng đại_mục) và không có giá trị nào bị thiếu. Sau khi tải dữ liệu, chúng tôi chia nó thành tập huấn luyện, tập xác thực và tập thử nghiệm, đồng thời chúng tôi chia tỷ lệ tất cả các tính năng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng, đào tạo, đánh giá và sử dụng MLP hồi quy bằng cách sử dụng API tuần tự để đưa ra dự đoán khá giống với những gì chúng tôi đã làm để phân loại. Sự khác biệt chính là thực tế là lớp đầu ra có một nơ-ron duy nhất (vì chúng ta chỉ muốn dự đoán một giá trị duy nhất) và không sử dụng hàm kích hoạt, và hàm mất mát là lỗi bình phương trung bình. Vì tập dữ liệu khá ồn ào, chúng tôi chỉ sử dụng một lớp ẩn duy nhất có ít tế bào thần kinh hơn trước, để tránh trang bị quá khớp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 837us/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 584us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng mô hình phức tạp bằng API chức năng (Functional API)\n",
    "Một ví dụ về mạng nơ-ron không tuần tự là mạng nơ-ron Rộng & Sâu.\n",
    "Kiến trúc mạng thần kinh này đã được Heng-Tze Cheng và cộng sự giới thiệu trong một bài báo năm 2016. Nó kết nối tất cả hoặc một phần đầu vào trực tiếp với lớp đầu ra, như trong Hình 10-13. Kiến trúc này giúp mạng nơ-ron có thể học được cả các mẫu sâu (sử dụng đường dẫn sâu) và các quy tắc đơn giản (thông qua đường dẫn ngắn). Ngược lại, MLP thông thường buộc tất cả dữ liệu phải chảy qua đầy đủ các lớp, do đó các mẫu đơn giản trong dữ liệu có thể bị bóp méo bởi chuỗi biến đổi này.\n",
    "\n",
    "![](images/10.13.png)\n",
    "\n",
    "*Hình 10.13 Wide and Deep Neural Network*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy xây dựng một mạng lưới thần kinh như vậy để giải quyết vấn đề nhà ở ở California:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy xem qua từng dòng của mã này:\n",
    "- Đầu tiên, chúng ta cần tạo một đối tượng `input_`. Điều này là cần thiết vì chúng ta có thể có nhiều đầu vào, như chúng ta sẽ thấy ở phần sau.\n",
    "- Tiếp theo, chúng ta tạo một lớp `Dense` với 30 tế bào thần kinh và sử dụng chức năng kích hoạt ReLU. Ngay sau khi nó được tạo, hãy lưu ý rằng chúng ta gọi nó giống như một hàm, chuyển nó là đầu vào. Đây là lý do tại sao nó được gọi là API chức năng. Lưu ý rằng chúng tôi chỉ nói với Keras rằng nó sẽ kết nối các lớp với nhau như thế nào, chưa có dữ liệu thực tế nào được xử lý.\n",
    "- Sau đó, chúng tôi tạo một lớp ẩn thứ hai và một lần nữa chúng tôi sử dụng nó như một hàm. Tuy nhiên, lưu ý rằng chúng tôi chuyển nó vào đầu ra của lớp ẩn đầu tiên.\n",
    "- Tiếp theo, chúng ta tạo một lớp `Concatenate()` và một lần nữa chúng ta ngay lập tức sử dụng nó như một hàm, để nối đầu vào và đầu ra của lớp ẩn thứ hai (bạn có thể thích hàm `keras.layers.concatenate()`, tạo một lớp `Concatenate` và ngay lập tức gọi nó với các đầu vào đã cho).\n",
    "- Sau đó, chúng tôi tạo lớp đầu ra, với một nơ-ron duy nhất và không có chức năng kích hoạt, và chúng tôi gọi nó giống như một hàm, chuyển nó là kết quả của phép ghép.\n",
    "- Cuối cùng, chúng tôi tạo Mô hình Keras, chỉ định đầu vào và đầu ra nào sẽ sử dụng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một khi bạn đã xây dựng mô hình Keras, mọi thứ giống hệt như trước đó, vì vậy không cần phải lặp lại nó ở đây: bạn phải biên dịch mô hình, đào tạo nó, đánh giá nó và sử dụng nó để đưa ra dự đoán.\n",
    "\n",
    "Nhưng điều gì sẽ xảy ra nếu bạn muốn gửi một tập hợp con các tính năng thông qua một đường dẫn rộng và tập hợp con khác nhau (có thể chồng lên nhau) thông qua đường dẫn sâu (xem Hình 10-14)? Trong trường hợp này, một giải pháp là sử dụng nhiều đầu vào. Ví dụ: giả sử chúng tôi muốn gửi 5 tính năng qua đường dẫn sâu (tính năng từ 0 đến 4) và 6 tính năng qua đường dẫn rộng (tính năng 2 đến 7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/10.14.png)\n",
    "\n",
    "*Hình 10.14 Xử lý nhiều đầu vào*\n",
    "\n",
    "Mã tự giải thích. Lưu ý rằng chúng tôi đã chỉ định `inputs = [input_A, input_B]`\n",
    "khi tạo mô hình. Bây giờ chúng ta có thể biên dịch mô hình như bình thường, nhưng khi chúng ta gọi phương thức `fit()`, thay vì truyền một ma trận đầu vào `X_train`, chúng ta phải truyền một cặp ma trận `(X_train_A, X_train_B)`: một cho mỗi đầu vào. Điều này cũng đúng với `X_valid` và cả `X_test` và `X_new` khi bạn gọi hàm `eval()` hoặc `predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2789 - val_loss: 2.3491\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8530 - val_loss: 0.9370\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.7243 - val_loss: 0.6847\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6617 - val_loss: 0.6149\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6199 - val_loss: 0.5806\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.5858 - val_loss: 0.5720\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5581 - val_loss: 0.5726\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.5507\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5124 - val_loss: 0.5443\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5452\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4837 - val_loss: 0.4943\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.4916\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.4672\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4579 - val_loss: 0.4454\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.4324\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4217\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4118\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4045\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.4024\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.3979\n",
      "162/162 [==============================] - 0s 698us/step - loss: 0.4264\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cũng có nhiều trường hợp sử dụng mà bạn có thể muốn có nhiều đầu ra:\n",
    "- Nhiệm vụ có thể yêu cầu nó, ví dụ như bạn có thể muốn xác định vị trí và phân loại đối tượng chính trong một bức tranh. Đây vừa là nhiệm vụ hồi quy (tìm tọa độ của tâm đối tượng, cũng như chiều rộng và chiều cao của nó) vừa là nhiệm vụ phân loại.\n",
    "- Tương tự, bạn có thể có nhiều tác vụ độc lập để thực hiện dựa trên cùng một dữ liệu. Chắc chắn, bạn có thể đào tạo một mạng nơ-ron cho mỗi tác vụ, nhưng trong nhiều trường hợp, bạn sẽ nhận được kết quả tốt hơn trên tất cả các tác vụ bằng cách đào tạo một mạng nơ-ron duy nhất với một đầu ra cho mỗi tác vụ. Điều này là do mạng nơ-ron có thể tìm hiểu các tính năng trong dữ liệu hữu ích trên các tác vụ.\n",
    "- Một trường hợp sử dụng khác là như một kỹ thuật chính quy hóa (tức là một ràng buộc đào tạo có mục tiêu là giảm trang bị quá mức và do đó cải thiện khả năng tổng quát hóa của mô hình). Ví dụ, bạn có thể muốn thêm một số đầu ra phụ trong kiến trúc mạng nơ-ron (xem Hình 10-15) để đảm bảo rằng phần bên dưới của mạng tự học được điều gì đó hữu ích mà không cần phụ thuộc vào phần còn lại của mạng.\n",
    "\n",
    "![](images/10.15.png)\n",
    "\n",
    "*Hình 10.15 Xử lý nhiều đầu ra - Đầu ra phụ trợ cho việc điều tiết hóa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, up to the main output layer\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "aux_output = keras.layers.Dense(1)(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                            outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mỗi đầu ra sẽ cần hàm tổn thất riêng, vì vậy khi biên dịch mô hình, chúng ta nên chuyển một danh sách các tổn thất (nếu chúng ta vượt qua một tổn thất duy nhất, Keras sẽ cho rằng phải sử dụng cùng một tổn thất cho tất cả các đầu ra). Theo mặc định, Keras sẽ tính toán tất cả các khoản lỗ này và chỉ cần cộng chúng lại để có được khoản lỗ cuối cùng được sử dụng để huấn luyện. Tuy nhiên, chúng tôi quan tâm nhiều hơn đến đầu ra chính hơn là đầu ra phụ (vì nó chỉ được sử dụng để chính quy hóa), vì vậy chúng tôi muốn cho sự mất mát của đầu ra chính có trọng lượng lớn hơn nhiều. May mắn thay, có thể thiết lập tất cả các trọng số giảm khi biên dịch mô hình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ khi chúng ta đào tạo mô hình, chúng ta cần cung cấp một số nhãn cho mỗi đầu ra. Trong ví dụ này, đầu ra chính và đầu ra phụ nên cố gắng dự đoán cùng một điều, vì vậy chúng nên sử dụng cùng một nhãn. Vì vậy, thay vì truyền `y_train`, chúng ta chỉ cần truyền `(y_train, y_train)` (và tương tự với `y_valid` và `y_test`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7605 - dense_31_loss: 0.6969 - dense_32_loss: 1.3328 - val_loss: 0.4787 - val_dense_31_loss: 0.4184 - val_dense_32_loss: 1.0212\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4767 - dense_31_loss: 0.4306 - dense_32_loss: 0.8917 - val_loss: 0.5872 - val_dense_31_loss: 0.5653 - val_dense_32_loss: 0.7840\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4477 - dense_31_loss: 0.4169 - dense_32_loss: 0.7249 - val_loss: 0.4334 - val_dense_31_loss: 0.4000 - val_dense_32_loss: 0.7337\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4292 - dense_31_loss: 0.4050 - dense_32_loss: 0.6477 - val_loss: 0.4077 - val_dense_31_loss: 0.3812 - val_dense_32_loss: 0.6463\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4208 - dense_31_loss: 0.4000 - dense_32_loss: 0.6084 - val_loss: 0.4698 - val_dense_31_loss: 0.4479 - val_dense_32_loss: 0.6664\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4128 - dense_31_loss: 0.3934 - dense_32_loss: 0.5868 - val_loss: 0.9002 - val_dense_31_loss: 0.9283 - val_dense_32_loss: 0.6473\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4168 - dense_31_loss: 0.3996 - dense_32_loss: 0.5712 - val_loss: 0.4262 - val_dense_31_loss: 0.4094 - val_dense_32_loss: 0.5775\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4049 - dense_31_loss: 0.3875 - dense_32_loss: 0.5612 - val_loss: 0.4024 - val_dense_31_loss: 0.3883 - val_dense_32_loss: 0.5298\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3978 - dense_31_loss: 0.3811 - dense_32_loss: 0.5479 - val_loss: 0.4060 - val_dense_31_loss: 0.3919 - val_dense_32_loss: 0.5329\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3930 - dense_31_loss: 0.3769 - dense_32_loss: 0.5380 - val_loss: 0.4102 - val_dense_31_loss: 0.3934 - val_dense_32_loss: 0.5618\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3900 - dense_31_loss: 0.3746 - dense_32_loss: 0.5282 - val_loss: 0.3723 - val_dense_31_loss: 0.3549 - val_dense_32_loss: 0.5291\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - dense_31_loss: 0.3709 - dense_32_loss: 0.5227 - val_loss: 0.3938 - val_dense_31_loss: 0.3727 - val_dense_32_loss: 0.5836\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3833 - dense_31_loss: 0.3687 - dense_32_loss: 0.5144 - val_loss: 0.3781 - val_dense_31_loss: 0.3580 - val_dense_32_loss: 0.5595\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3781 - dense_31_loss: 0.3635 - dense_32_loss: 0.5096 - val_loss: 0.3604 - val_dense_31_loss: 0.3435 - val_dense_32_loss: 0.5122\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3748 - dense_31_loss: 0.3608 - dense_32_loss: 0.5004 - val_loss: 0.3535 - val_dense_31_loss: 0.3354 - val_dense_32_loss: 0.5164\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3713 - dense_31_loss: 0.3573 - dense_32_loss: 0.4965 - val_loss: 0.3470 - val_dense_31_loss: 0.3328 - val_dense_32_loss: 0.4750\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3685 - dense_31_loss: 0.3549 - dense_32_loss: 0.4902 - val_loss: 0.3767 - val_dense_31_loss: 0.3608 - val_dense_32_loss: 0.5193\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - dense_31_loss: 0.3515 - dense_32_loss: 0.4842 - val_loss: 0.3727 - val_dense_31_loss: 0.3537 - val_dense_32_loss: 0.5441\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3657 - dense_31_loss: 0.3530 - dense_32_loss: 0.4801 - val_loss: 0.3402 - val_dense_31_loss: 0.3257 - val_dense_32_loss: 0.4707\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - dense_31_loss: 0.3495 - dense_32_loss: 0.4756 - val_loss: 0.3680 - val_dense_31_loss: 0.3518 - val_dense_32_loss: 0.5139\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi chúng tôi đánh giá mô hình, Keras sẽ trả lại tổng số lỗ cũng như tất cả các khoản lỗ riêng lẻ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3536 - dense_31_loss: 0.3418 - dense_32_loss: 0.4595\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự, phương thức `predict()` sẽ trả về các dự đoán cho mỗi đầu ra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng mô hình động bằng API phân lớp (Subclassing API)\n",
    "Cả **Sequential API** và **Functional API** đều mang tính chất khai báo: bạn bắt đầu bằng cách khai báo lớp nào bạn muốn sử dụng và cách chúng được kết nối và chỉ sau đó, bạn mới có thể bắt đầu cung cấp cho mô hình một số dữ liệu để đào tạo hoặc suy luận. Điều này có nhiều ưu điểm: mô hình có thể dễ dàng được lưu, sao chép, chia sẻ, cấu trúc của nó có thể được hiển thị và phân tích, khung công tác có thể suy ra hình dạng và kiểm tra loại, do đó, lỗi có thể được phát hiện sớm (tức là trước khi bất kỳ dữ liệu nào đi qua mô hình ). Nó cũng khá dễ gỡ lỗi, vì toàn bộ mô hình chỉ là một biểu đồ tĩnh của các lớp. Nhưng mặt trái của nó chỉ là: nó tĩnh. Một số mô hình liên quan đến các vòng lặp, các hình dạng khác nhau, phân nhánh có điều kiện và các hành vi động khác. Đối với những trường hợp như vậy, hoặc đơn giản nếu bạn thích phong cách lập trình bắt buộc hơn, **Subclassing API** là dành cho bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # xử lý các nhóm tiêu chuẩn (ví dụ: name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ này trông rất giống với Functional API, ngoại trừ việc chúng ta không cần tạo các đầu vào, chúng ta chỉ sử dụng đối số đầu vào cho phương thức `call()` và chúng ta tách việc tạo các lớp15 trong hàm tạo khỏi việc sử dụng chúng trong lệnh `call()` phương pháp. Tuy nhiên, sự khác biệt lớn là bạn có thể làm bất cứ điều gì bạn muốn trong phương thức `call()`: vòng lặp `for`, câu lệnh `if`, hoạt động TensorFlow cấp thấp, trí tưởng tượng của bạn là giới hạn (xem Chương 12)! Điều này làm cho nó trở thành một API tuyệt vời cho các nhà nghiên cứu thử nghiệm những ý tưởng mới.\n",
    "\n",
    "Tuy nhiên, tính linh hoạt bổ sung này phải trả giá: kiến trúc mô hình của bạn bị ẩn\n",
    "trong phương thức `call()`, vì vậy Keras không thể dễ dàng kiểm tra nó, nó không thể lưu hoặc sao chép nó và khi bạn gọi phương thức `Summary()`, bạn chỉ nhận được danh sách các lớp mà không có bất kỳ thông tin nào về cách chúng được kết nối với nhau . Hơn nữa, Keras không thể kiểm tra các loại và hình dạng trước thời hạn, và càng dễ mắc lỗi. Vì vậy, trừ khi bạn thực sự cần sự linh hoạt bổ sung đó, bạn có thể nên sử dụng API tuần tự hoặc API chức năng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu và khôi phục một mô hình\n",
    "Lưu một mô hình Keras được đào tạo đơn giản như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras sẽ lưu cả kiến trúc của mô hình (bao gồm siêu tham số của mọi lớp) và giá trị của tất cả các thông số mô hình cho mọi lớp (ví dụ: trọng số và độ lệch kết nối), sử dụng định dạng HDF5. Nó cũng lưu trình tối ưu hóa (bao gồm các siêu tham số của nó và bất kỳ trạng thái nào mà nó có thể có).\n",
    "Thông thường, bạn sẽ có một tập lệnh huấn luyện một mô hình và lưu nó, và một hoặc nhiều tập lệnh (hoặc dịch vụ web) tải mô hình và sử dụng nó để đưa ra dự đoán. Tải mô hình cũng dễ dàng như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_weights(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng Callbacks\n",
    "Phương thức `fit()` chấp nhận một đối số `callbacks` cho phép bạn chỉ định danh sách các đối tượng mà Keras sẽ gọi trong quá trình huấn luyện khi bắt đầu và kết thúc huấn luyện, khi bắt đầu và kết thúc mỗi epoch thậm chí trước và sau khi xử lý mỗi đợt. Ví dụ: lệnh gọi lại `ModelCheckpoint` lưu các điểm kiểm tra của mô hình của bạn theo khoảng thời gian đều đặn trong quá trình đào tạo, theo mặc định ở cuối mỗi epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and compile the model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hơn nữa, nếu bạn sử dụng validation set trong quá trình đào tạo, bạn có thể đặt `save_best_only = True` khi tạo `ModelCheckpoint`. Trong trường hợp này, nó sẽ chỉ lưu mô hình của bạn khi hiệu suất của nó trên bộ xác thực là tốt nhất cho đến nay. Bằng cách này, bạn không cần phải lo lắng về việc đào tạo quá lâu và trang bị quá nhiều bộ đào tạo: chỉ cần khôi phục mô hình cuối cùng được lưu sau khi đào tạo và đây sẽ là mô hình tốt nhất trên bộ xác nhận. Đây là một cách đơn giản để thực hiện dừng sớm (được giới thiệu trong Chương 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                                save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một cách khác để thực hiện dừng sớm là chỉ cần sử dụng lệnh gọi lại `EarlyStopping`. Nó sẽ làm gián đoạn quá trình đào tạo khi nó không đo lường được tiến trình nào trên bộ xác thực cho một số kỷ nguyên (được xác định bởi đối số kiên nhẫn) và nó sẽ tùy chọn quay trở lại mô hình tốt nhất. Bạn có thể kết hợp cả hai lệnh gọi lại để vừa lưu các điểm kiểm tra của mô hình (trong trường hợp máy tính của bạn gặp sự cố), vừa thực sự làm gián đoạn quá trình đào tạo sớm khi không còn tiến bộ (để tránh lãng phí thời gian và tài nguyên):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                            restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Số lượng epoch có thể được đặt thành một giá trị lớn vì quá trình đào tạo sẽ tự động dừng khi không còn tiến bộ nữa. Hơn nữa, không cần khôi phục mô hình tốt nhất đã lưu trong trường hợp này vì lệnh gọi lại `EarlyStopping` sẽ theo dõi các trọng lượng tốt nhất và khôi phục chúng cho chúng tôi khi kết thúc quá trình đào tạo.\n",
    "\n",
    "Nếu bạn cần kiểm soát thêm, bạn có thể dễ dàng viết các lệnh gọi lại tùy chỉnh của riêng mình. Ví dụ: lệnh gọi lại tùy chỉnh sau sẽ hiển thị tỷ lệ giữa mất xác thực và mất đào tạo trong quá trình đào tạo (ví dụ: để phát hiện trang bị quá mức):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trực quan hóa bằng TensorBoard\n",
    "TensorBoard là một công cụ trực quan hóa tương tác tuyệt vời mà bạn có thể sử dụng để xem các đường cong học tập trong quá trình đào tạo, so sánh các đường cong học tập giữa nhiều lần chạy, trực quan hóa biểu đồ tính toán, phân tích thống kê đào tạo, xem hình ảnh được tạo bởi mô hình của bạn, trực quan hóa dữ liệu đa chiều phức tạp được chiếu xuống 3D và tự động được nhóm lại cho bạn và hơn thế nữa! Công cụ này được cài đặt tự động khi bạn cài đặt TensorFlow, vì vậy bạn đã có nó!\n",
    "\n",
    "Để sử dụng nó, bạn phải sửa đổi chương trình của mình để nó xuất ra dữ liệu bạn muốn trực quan hóa thành các tệp nhật ký nhị phân đặc biệt được gọi là **event files**. Mỗi bản ghi dữ liệu nhị phân được gọi là **summary**. Máy chủ TensorBoard sẽ theo dõi thư mục nhật ký và nó sẽ tự động nhận các thay đổi và cập nhật các hình ảnh trực quan: điều này cho phép bạn trực quan hóa dữ liệu trực tiếp (với độ trễ ngắn), chẳng hạn như các đường cong học tập trong quá trình đào tạo. Nói chung, bạn muốn trỏ máy chủ TensorBoard đến thư mục nhật ký gốc và định cấu hình chương trình của bạn để chương trình ghi vào một thư mục con khác mỗi khi nó chạy. Bằng cách này, cùng một phiên bản máy chủ TensorBoard sẽ cho phép bạn trực quan hóa và so sánh dữ liệu từ nhiều lần chạy chương trình của mình mà không làm mọi thứ lẫn lộn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_06_06-15_00_09'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và đó là tất cả những gì cần làm! Nó khó có thể dễ sử dụng hơn. Nếu bạn chạy mã này, lệnh gọi lại TensorBoard sẽ đảm nhận việc tạo thư mục nhật ký cho bạn (cùng với các thư mục mẹ của nó nếu cần) và trong quá trình đào tạo, nó sẽ tạo các tệp sự kiện và viết tóm tắt cho chúng. Sau khi chạy chương trình lần thứ hai (có thể thay đổi một số giá trị siêu tham số), bạn sẽ kết thúc với một cấu trúc thư mục tương tự như sau:\n",
    "\n",
    "```\n",
    "my_logs\n",
    "├── run_2019_01_16-16_51_02\n",
    "│ └── events.out.tfevents.1547628669.mycomputer.local.v2\n",
    "└── run_2019_01_16-16_56_50\n",
    "└── events.out.tfevents.1547629020.mycomputer.local.v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, bạn cần khởi động máy chủ TensorBoard. Nếu bạn đã cài đặt TensorFlow trong virtualenv, bạn nên kích hoạt nó. Tiếp theo, chạy lệnh sau tại thư mục gốc của dự án (hoặc từ bất kỳ nơi nào khác miễn là bạn trỏ đến thư mục nhật ký thích hợp). Nếu shell của bạn không thể tìm thấy tập lệnh tensorboard, thì bạn phải cập nhật biến môi trường PATH của mình để nó chứa thư mục mà tập lệnh đã được cài đặt (cách khác, bạn chỉ có thể thay thế tensorboard bằng python3 -m tensor board.main)\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "TensorBoard 2.0.0 at http://mycomputer.local:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "Cuối cùng, mở trình duyệt web tới http://localhost:6006. Bạn sẽ thấy giao diện web của TensorBoard. Nhấp vào tab SCALARS để xem các đường cong học tập (xem Hình 10-16). Lưu ý rằng mất tập luyện đã giảm đi đáng kể trong cả hai lần chạy, nhưng lần chạy thứ hai giảm nhanh hơn nhiều. Thật vậy, chúng tôi đã sử dụng tốc độ học tập lớn hơn bằng cách `optimizer = keras.optimizers.SGD(lr = 0,05)` thay `optimizer=\"sgd\"`, được mặc định là learning rate là 0,001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/10.16.png)\n",
    "\n",
    "*Hình 10.16 Hình dung đường cong học tập với TensorBoard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
